{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2c18e51-6a14-4a78-be3a-fcd572e58ef4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql.functions import col, udf, lower, substring, broadcast\n",
    "from pyspark.sql.types import StringType, ArrayType, FloatType\n",
    "from gensim.models import Word2Vec\n",
    "from scipy.spatial.distance import cosine\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "823c84fc-cc13-427f-94dc-0ad08ad27685",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_location_4 = \"/FileStore/tables/linkedin_124k_kaggle.parquet\"\n",
    "file_type = \"parquet\"\n",
    "\n",
    "linkedin_124k_kaggle = spark.read.format(file_type).load(file_location_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23b41751-ccf0-41dc-b47b-fdefe3796340",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "classification = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(file_location_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2df5d973-bb87-4f6f-8fd8-4ab200eaf212",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Stopwords list for cleaning descriptions\n",
    "stopwords = set([\n",
    "    # Conjunctions and prepositions\n",
    "    \"a\", \"an\", \"the\", \"and\", \"or\", \"but\", \"nor\", \"so\", \"yet\", \"for\", \"because\", \"since\", \"although\", \"though\", \n",
    "    \"whereas\", \"while\", \"unless\", \"until\", \"whether\", \"if\", \"then\", \"else\", \"beside\", \"between\", \"among\", \"through\",\n",
    "    \"against\", \"along\", \"upon\", \"before\", \"after\", \"above\", \"below\", \"within\", \"without\", \"during\", \"across\", \"off\", \n",
    "    \"via\", \"per\", \"amid\", \"amongst\", \"throughout\", \"whereby\", \"wherein\",\n",
    "\n",
    "    # Question words\n",
    "    \"what\", \"who\", \"whom\", \"which\", \"whose\", \"where\", \"when\", \"why\", \"how\", \"whenever\", \"wherever\", \n",
    "    \"whichever\", \"whoever\", \"whomever\",\n",
    "\n",
    "    # Numbers (both words and digits)\n",
    "    \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\", \"ten\", \"eleven\", \"twelve\", \n",
    "    \"thirteen\", \"fourteen\", \"fifteen\", \"sixteen\", \"seventeen\", \"eighteen\", \"nineteen\", \"twenty\", \n",
    "    \"thirty\", \"forty\", \"fifty\", \"sixty\", \"seventy\", \"eighty\", \"ninety\", \"hundred\", \"thousand\", \n",
    "    \"million\", \"billion\", \"trillion\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\",\n",
    "\n",
    "    # Time-related words\n",
    "    \"now\", \"then\", \"later\", \"soon\", \"yesterday\", \"today\", \"tomorrow\", \"tonight\", \"afterwards\", \n",
    "    \"earlier\", \"eventually\", \"recently\", \"previously\", \"lately\", \"once\", \"twice\", \"thrice\", \n",
    "    \"daily\", \"weekly\", \"monthly\", \"yearly\", \"always\", \"never\", \"sometimes\", \"often\", \"rarely\", \n",
    "    \"frequently\", \"occasionally\", \"asap\", \"immediately\", \"currently\", \"ongoing\", \"permanent\", \"temporary\",\n",
    "\n",
    "    # Directions and locations\n",
    "    \"up\", \"down\", \"left\", \"right\", \"front\", \"back\", \"forward\", \"backward\", \"toward\", \"away\", \n",
    "    \"inside\", \"outside\", \"upward\", \"downward\", \"north\", \"south\", \"east\", \"west\", \"northeast\", \n",
    "    \"northwest\", \"southeast\", \"southwest\", \"international\", \"regional\", \"global\", \"local\",\n",
    "\n",
    "    # Common terms in job descriptions\n",
    "    \"job\", \"position\", \"title\", \"career\", \"industry\", \"field\", \"department\", \"division\", \n",
    "    \"team\", \"section\", \"branch\", \"office\", \"company\", \"organization\", \"firm\", \"business\", \n",
    "    \"enterprise\", \"corporation\", \"startup\", \"venture\", \"client\", \"customer\", \"stakeholder\", \n",
    "    \"partner\", \"investor\", \"shareholder\", \"personnel\", \"staff\", \"employee\", \"applicant\", \n",
    "    \"candidate\", \"recruit\", \"hire\", \"vacancy\", \"opening\",\n",
    "\n",
    "    # General verbs (to avoid affecting relevant skills)\n",
    "    \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \n",
    "    \"do\", \"does\", \"did\", \"doing\", \"can\", \"could\", \"shall\", \"should\", \"will\", \"would\", \n",
    "    \"may\", \"might\", \"must\", \"ought\", \"need\", \"dare\",\n",
    "\n",
    "    # Technical terms found in reports, documents, and publications\n",
    "    \"figure\", \"table\", \"section\", \"chapter\", \"paragraph\", \"appendix\", \"reference\", \"citation\", \n",
    "    \"footnote\", \"index\", \"abstract\", \"conclusion\", \"introduction\", \"summary\", \"discussion\", \n",
    "    \"results\", \"methodology\", \"analysis\", \"data\", \"survey\", \"experiment\", \"variable\", \n",
    "    \"statistic\", \"finding\", \"trend\", \"observation\", \"estimation\", \"approximation\", \n",
    "    \"prediction\", \"evaluation\",\n",
    "\n",
    "    # Common phrases in job advertisements\n",
    "    \"opportunity\", \"competitive\", \"growth\", \"develop\", \"training\", \"support\", \"exciting\", \"rewarding\", \n",
    "    \"innovative\", \"cutting-edge\", \"leading\", \"established\", \"recognized\", \"renowned\", \"progressive\", \n",
    "    \"collaborative\", \"inclusive\", \"diverse\", \"teamwork\", \"mentoring\", \"coaching\", \"partnership\", \n",
    "    \"leadership\", \"visionary\", \"impactful\", \"driven\", \"dedicated\", \"empowered\", \"engaging\"\n",
    "])\n",
    "\n",
    "# Function to clean text and remove stopwords\n",
    "def clean_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    \n",
    "    text = text.lower()  # Convert text to lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stopwords]  # Remove stopwords\n",
    "    return \" \".join(words)\n",
    "\n",
    "clean_text_udf = udf(clean_text, StringType())\n",
    "\n",
    "# Clean the description and other text fields in the tables\n",
    "linkedin_124k_kaggle = linkedin_124k_kaggle.withColumn(\"clean_description\", clean_text_udf(lower(col(\"description\"))))\n",
    "classification = classification.withColumn(\"clean_onet_description\", clean_text_udf(lower(col(\"O*NET-SOC 2019 Description\"))))\n",
    "\n",
    "# Truncate the description to 600 characters after cleaning\n",
    "linkedin_124k_kaggle = linkedin_124k_kaggle.withColumn(\"short_description\", substring(col(\"clean_description\"), 1, 600))\n",
    "classification = classification.withColumn(\"short_onet_description\", substring(col(\"clean_onet_description\"), 1, 600))\n",
    "\n",
    "# Use Broadcast to speed up classification\n",
    "classification = broadcast(classification)\n",
    "\n",
    "# Train Word2Vec on all descriptions from both tables\n",
    "job_sentences = [row[\"short_description\"].split() for row in linkedin_124k_kaggle.select(\"short_description\").distinct().collect()]\n",
    "onet_sentences = [row[\"short_onet_description\"].split() for row in classification.select(\"short_onet_description\").distinct().collect()]\n",
    "\n",
    "word2vec_model = Word2Vec(job_sentences + onet_sentences, vector_size=100, window=5, min_count=1, workers=8)\n",
    "\n",
    "# Generate vectors for descriptions in both tables\n",
    "def get_vector(description):\n",
    "    words = description.split()\n",
    "    vectors = [word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0).tolist()  # Compute mean vector\n",
    "    else:\n",
    "        return np.zeros(word2vec_model.vector_size).tolist()  # Return zero vector if no valid words\n",
    "\n",
    "get_vector_udf = udf(get_vector, ArrayType(FloatType()))\n",
    "\n",
    "linkedin_124k_kaggle = linkedin_124k_kaggle.withColumn(\"description_vector\", get_vector_udf(col(\"short_description\")))\n",
    "classification = classification.withColumn(\"onet_vector\", get_vector_udf(col(\"short_onet_description\")))\n",
    "\n",
    "# Match each title based on vector similarity\n",
    "onet_vectors = classification.select(\"O*NET-SOC 2019 Title\", \"onet_vector\").rdd.collectAsMap()\n",
    "\n",
    "def find_best_match(description_vector):\n",
    "    if not description_vector:\n",
    "        return \"Other\"\n",
    "    \n",
    "    best_match = \"Other\"\n",
    "    best_score = float(\"inf\")\n",
    "    \n",
    "    for onet_title, onet_vector in onet_vectors.items():\n",
    "        distance = cosine(description_vector, onet_vector)\n",
    "        if distance < best_score:\n",
    "            best_score = distance\n",
    "            best_match = onet_title\n",
    "    \n",
    "    return best_match\n",
    "\n",
    "find_best_match_udf = udf(find_best_match, StringType())\n",
    "\n",
    "linkedin_124k_kaggle = linkedin_124k_kaggle.withColumn(\"title_elad_new\", find_best_match_udf(col(\"description_vector\")))\n",
    "\n",
    "# Check unique values before and after matching\n",
    "columns_to_check = [\"title\", \"title_elad_new\"]\n",
    "\n",
    "for col_name in columns_to_check:\n",
    "    unique_count = linkedin_124k_kaggle.select(col(col_name)).distinct().count()\n",
    "    print(f\"Column: {col_name} | Unique values: {unique_count}\")\n",
    "\n",
    "# Display sample results\n",
    "linkedin_124k_kaggle.select(\"title\", \"title_elad_new\").distinct().show(50, truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "NLP - implementation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}